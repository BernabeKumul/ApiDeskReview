"""
Script para procesar TODOS los documentos del JSON con el modelo BAAI/bge-m3.
Evita duplicados automÃ¡ticamente.
"""
import asyncio
import logging
from app.services.baai_document_processor import baai_document_processor

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def process_all_documents():
    """Procesa todos los documentos del JSON con BAAI/bge-m3."""
    
    print("ğŸš€ Iniciando procesamiento de TODOS los documentos con BAAI/bge-m3...")
    print("ğŸ“„ Leyendo documentos desde JSON/AzzuleAI.AIDocuments.json")
    print("ğŸ” Verificando duplicados automÃ¡ticamente...")
    print("âš¡ Usando modelo BAAI/bge-m3 (1024 dimensiones)")
    print("=" * 80)
    
    try:
        # Procesar todos los documentos sin lÃ­mite
        result = await baai_document_processor.process_all_documents(limit=None)
        
        print("\n" + "=" * 80)
        print("ğŸ“Š RESULTADOS DEL PROCESAMIENTO:")
        print("=" * 80)
        print(f"âœ… Ã‰xito: {result['success']}")
        print(f"ğŸ“ Mensaje: {result['message']}")
        print(f"ğŸ”„ Documentos procesados: {result['processed']}")
        print(f"â­ï¸  Documentos saltados (duplicados): {result['skipped']}")
        print(f"âŒ Errores: {result['errors']}")
        print(f"ğŸ“Š Total de documentos en JSON: {result['total_documents']}")
        
        if result.get('collection_stats'):
            stats = result['collection_stats']
            print(f"\nğŸ“ˆ ESTADÃSTICAS DE LA COLECCIÃ“N:")
            print(f"   - Nombre: {stats.get('collection_name', 'N/A')}")
            print(f"   - Puntos en la colecciÃ³n: {stats.get('points_count', 0)}")
            print(f"   - TamaÃ±o del vector: {stats.get('vector_size', 0)}")
            print(f"   - Segmentos: {stats.get('segments_count', 0)}")
            print(f"   - Estado: {stats.get('status', 'N/A')}")
        
        # Calcular porcentajes
        total = result['processed'] + result['skipped'] + result['errors']
        if total > 0:
            processed_pct = (result['processed'] / total) * 100
            skipped_pct = (result['skipped'] / total) * 100
            error_pct = (result['errors'] / total) * 100
            
            print(f"\nğŸ“Š PORCENTAJES:")
            print(f"   - Procesados: {processed_pct:.1f}%")
            print(f"   - Saltados: {skipped_pct:.1f}%")
            print(f"   - Errores: {error_pct:.1f}%")
        
        if result['success']:
            print("\nğŸ‰ Â¡PROCESAMIENTO COMPLETADO EXITOSAMENTE!")
            print(f"âœ… Se procesaron {result['processed']} documentos nuevos")
            if result['skipped'] > 0:
                print(f"â­ï¸  Se saltaron {result['skipped']} documentos duplicados")
        else:
            print("\nâŒ ERROR EN EL PROCESAMIENTO")
            print(f"ğŸ’¬ {result['message']}")
        
        return result
        
    except Exception as e:
        print(f"\nâŒ ERROR CRÃTICO: {e}")
        logger.error(f"Error en procesamiento masivo: {e}")
        return {
            "success": False,
            "message": f"Error crÃ­tico: {str(e)}",
            "processed": 0,
            "skipped": 0,
            "errors": 1
        }

if __name__ == "__main__":
    print("ğŸ§ª Iniciando procesamiento masivo de documentos con BAAI/bge-m3...")
    print("âš ï¸  Este proceso puede tomar varios minutos...")
    print("ğŸ’¾ El modelo BAAI/bge-m3 se descargarÃ¡ automÃ¡ticamente si es necesario")
    print()
    
    # Ejecutar procesamiento
    result = asyncio.run(process_all_documents())
    
    print("\nğŸ Proceso finalizado!")
    if result['success']:
        print("âœ… Todos los documentos han sido procesados exitosamente")
    else:
        print("âŒ Hubo errores durante el procesamiento") 